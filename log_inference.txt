
üì• Loading file: ../debug_wavs/sample_00.wav
üîç [pydub] Raw frame_rate   : 16000
üîç [pydub] Sample width     : 4 bytes (32 bits)
üîç [pydub] Channels         : 1
üîç [pydub] Duration (ms)    : 2375 ms
üß™ [pydub] Type of array     : <class 'array.array'>, dtype: int16
üß™ [pydub] First 10 samples  : array('h', [0, 0, -1, 0, 0, 0, 1, 3, 9, 11])
‚úÖ [pydub] Waveform shape    : torch.Size([1, 38000])
üìä [pydub] Min: -22944.00, Max: 24431.00, Mean: -0.01

üîÅ [Compare] Loading with torchaudio.load()
‚úÖ [torchaudio] shape        : torch.Size([1, 38000]), sample_rate: 16000
üìä [torchaudio] Min: -0.7002, Max: 0.7456, Mean: -0.0000
üìè Diff (mean abs): 0.0000 (assuming torchaudio gives normalized)
========== üîß CONFIG SUMMARY ==========
  chunk_size               = 64
  left_context_size        = 128
  right_context_size       = 128
  subsampling_factor       = 8
  conv_kernel_size         = 15
  conv_lorder              = 7
  num_blocks               = 17
  hidden_dim (_output_size)= 512
  attention_heads          = 8
  Input shape              = torch.Size([1, 236, 80])
=======================================

üßÆ CALCULATED CONTEXT INFO
  total_batch_duration     = 1800
  max_len (frame count)    = 89999
  multiply_n               = 175
  truncated_context_size   = 11200
  rel_right_context_size   = 17408


üì¶ Chunk 0
  Input chunk frame idx: 0 ‚Üí 236
  Input x shape         : torch.Size([1, 236, 80])
  x_len                 : [236]

================= üß© [Encoder.forward_parallel_chunk] START =================
üì• Input shape: torch.Size([1, 236, 80]), xs_origin_lens: [236]
‚öôÔ∏è chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
üìè Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
üîπ Sample 0: original_len=236, padded_len=519, pad_frames=283, n_chunks=1, offset=0

üß± Total chunked xs shape: torch.Size([1, 519, 80])
üìê xs_lens (post chunk): torch.Size([1]), total_chunks: 1
‚úÖ Applied Global CMVN
üéõÔ∏è Embedded xs shape: torch.Size([1, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
üßÆ att_mask shape: torch.Size([1, 1, 320]), mask_pad shape: torch.Size([1, 1, 78])
üß© Layer 0: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 0
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 1: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 1
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 2: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 2
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 3: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 3
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 4: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 4
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 5: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 5
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 6: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 6
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 7: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 7
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 8: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 8
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 9: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 9
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 10: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 10
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 11: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 11
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 12: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 12
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 13: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 13
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 14: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 14
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 15: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 15
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üß© Layer 16: xs shape after layer = torch.Size([1, 64, 512])
	üß© Layer 16
		ChunkFormerEncoderLayer(
  (self_attn): StreamingRelPositionMultiHeadedAttention(
    (linear_q): Linear(in_features=512, out_features=512, bias=True)
    (linear_k): Linear(in_features=512, out_features=512, bias=True)
    (linear_v): Linear(in_features=512, out_features=512, bias=True)
    (linear_out): Linear(in_features=512, out_features=512, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear_pos): Linear(in_features=512, out_features=512, bias=False)
  )
  (feed_forward): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (feed_forward_macaron): PositionwiseFeedForward(
    (w_1): Linear(in_features=512, out_features=2048, bias=True)
    (activation): SiLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (w_2): Linear(in_features=2048, out_features=512, bias=True)
  )
  (conv_module): ConvolutionModule(
    (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
    (depthwise_conv): Conv1d(512, 512, kernel_size=(15,), stride=(1,), groups=512)
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (activation): SiLU()
  )
  (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_ff_macaron): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
üìè Applied LayerNorm after encoder
üì§ Final offset: [28]

‚úÖ [Encoder Output] xs: torch.Size([1, 64, 512]), xs_lens: [28], n_chunks: [1]
====================================================================

  encoder_outs shape    : torch.Size([1, 64, 512])
  encoder_lens          : [28]
  framewise_ids shape   : torch.Size([28])
  framewise_ids (first 10): [0, 0, 0, 0, 4657, 0, 0, 6324, 0, 0]

üìä Total full_framewise_ids shape: torch.Size([28])
    Sample token IDs (first 20): [0, 0, 0, 0, 4657, 0, 0, 6324, 0, 0, 5854, 0, 0, 6819, 0, 2983, 0, 0, 1635, 0]

üìù Decoded segments (first 3):
  ‚Üí {'decode': ' n·ª≠a v√≤ng tr√°i ƒë·∫•t h∆°n b·∫£y nƒÉm', 'start': '00:00:00:000', 'end': '00:00:02:160'}

‚úÖ Final transcript:  n·ª≠a v√≤ng tr√°i ƒë·∫•t h∆°n b·∫£y nƒÉm
üü¢ Prediction     :  n·ª≠a v√≤ng tr√°i ƒë·∫•t h∆°n b·∫£y nƒÉm
üîµ Ground Truth   : n·ª≠a v√≤ng tr√°i ƒë·∫•t h∆°n b·∫£y nƒÉm
‚ùå WER            : 0.0
