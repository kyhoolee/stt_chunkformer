{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fd1ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ Loaded checkpoint from: ../../chunkformer-large-vie/pytorch_model.bin\n",
      "üì¶ Checkpoint keys: ['encoder.global_cmvn.mean', 'encoder.global_cmvn.istd', 'encoder.embed.out.weight', 'encoder.embed.out.bias', 'encoder.embed.conv.0.weight'] ... (total 813)\n",
      "üîç AED decoder head included in checkpoint? ‚úÖ YES\n",
      "üìä Model total params: 113,852,240, trainable: 113,852,240\n",
      "‚úÖ Loaded state_dict with:\n",
      "   üî∫ Missing keys: 2\n",
      "     - encoder.ctc.ctc_lo.weight\n",
      "     - encoder.ctc.ctc_lo.bias\n",
      "   ‚ö†Ô∏è Unexpected keys in checkpoint: 166\n",
      "     - decoder.left_decoder.embed.0.weight\n",
      "     - decoder.left_decoder.after_norm.weight\n",
      "     - decoder.left_decoder.after_norm.bias\n",
      "     - decoder.left_decoder.output_layer.weight\n",
      "     - decoder.left_decoder.output_layer.bias\n",
      "     - decoder.left_decoder.decoders.0.self_attn.linear_q.weight\n",
      "     - decoder.left_decoder.decoders.0.self_attn.linear_q.bias\n",
      "     - decoder.left_decoder.decoders.0.self_attn.linear_k.weight\n",
      "     - decoder.left_decoder.decoders.0.self_attn.linear_k.bias\n",
      "     - decoder.left_decoder.decoders.0.self_attn.linear_v.weight\n",
      "     ...\n",
      "‚úÖ Done! Saved model structure to folder: model_architect\n"
     ]
    }
   ],
   "source": [
    "# chunkformer_vpb/inference/dump_model_structure.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from chunkformer_vpb.model_utils import init, dump_module_structure\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # === Config ===\n",
    "    model_checkpoint = \"../../chunkformer-large-vie\"  # adjust if needed\n",
    "    output_dir = \"model_architect\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # === Load model ===\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model, char_dict = init(model_checkpoint, device)\n",
    "    model.eval()\n",
    "\n",
    "    # === Dump full model ===\n",
    "    dump_module_structure(model, os.path.join(output_dir, \"full_model.txt\"), \"Full ASRModel\")\n",
    "\n",
    "    # === Dump encoder ===\n",
    "    dump_module_structure(model.encoder, os.path.join(output_dir, \"encoder.txt\"), \"Encoder\")\n",
    "\n",
    "    # === Dump CTC head ===\n",
    "    dump_module_structure(model.ctc, os.path.join(output_dir, \"ctc.txt\"), \"CTC Head\")\n",
    "\n",
    "    # === Optional: Dump decoder if exists ===\n",
    "    if hasattr(model, \"decoder\"):\n",
    "        dump_module_structure(model.decoder, os.path.join(output_dir, \"decoder.txt\"), \"Decoder\")\n",
    "\n",
    "    print(f\"‚úÖ Done! Saved model structure to folder: {output_dir}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done! Saved model structure to folder: model_architect\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07c2b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßÆ === MODEL PARAMETER SUMMARY ===\n",
      "üîé Full Model\n",
      "   ‚Ä¢ Total parameters       : 113,852,240\n",
      "   ‚Ä¢ Trainable parameters   : 113,852,240\n",
      "   ‚Ä¢ Frozen parameters      : 0\n",
      "   ‚Ä¢ Estimated size (float32): 434.31 MB\n",
      "\n",
      "üîé Encoder\n",
      "   ‚Ä¢ Total parameters       : 113,852,240\n",
      "   ‚Ä¢ Trainable parameters   : 113,852,240\n",
      "   ‚Ä¢ Frozen parameters      : 0\n",
      "   ‚Ä¢ Estimated size (float32): 434.31 MB\n",
      "\n",
      "üîé CTC Head\n",
      "   ‚Ä¢ Total parameters       : 3,586,896\n",
      "   ‚Ä¢ Trainable parameters   : 3,586,896\n",
      "   ‚Ä¢ Frozen parameters      : 0\n",
      "   ‚Ä¢ Estimated size (float32): 13.68 MB\n",
      "\n",
      "‚úÖ Done! Saved model structure to folder: model_architect\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from chunkformer_vpb.model_utils import init, dump_module_structure\n",
    "\n",
    "def summarize_model_parameters(model, name=\"Model\"):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    frozen_params = total_params - trainable_params\n",
    "    size_mb = total_params * 4 / (1024**2)  # 4 bytes per float32 param\n",
    "\n",
    "    print(f\"üîé {name}\")\n",
    "    print(f\"   ‚Ä¢ Total parameters       : {total_params:,}\")\n",
    "    print(f\"   ‚Ä¢ Trainable parameters   : {trainable_params:,}\")\n",
    "    print(f\"   ‚Ä¢ Frozen parameters      : {frozen_params:,}\")\n",
    "    print(f\"   ‚Ä¢ Estimated size (float32): {size_mb:.2f} MB\\n\")\n",
    "    return total_params, trainable_params, size_mb\n",
    "\n",
    "def main():\n",
    "    # === Config ===\n",
    "    model_checkpoint = \"../../chunkformer-large-vie\"  # adjust if needed\n",
    "    output_dir = \"model_architect\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # === Load model ===\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model, char_dict = init(model_checkpoint, device)\n",
    "    model.eval()\n",
    "\n",
    "    # === Dump structures ===\n",
    "    dump_module_structure(model, os.path.join(output_dir, \"full_model.txt\"), \"Full ASRModel\")\n",
    "    dump_module_structure(model.encoder, os.path.join(output_dir, \"encoder.txt\"), \"Encoder\")\n",
    "    dump_module_structure(model.ctc, os.path.join(output_dir, \"ctc.txt\"), \"CTC Head\")\n",
    "    if hasattr(model, \"decoder\"):\n",
    "        dump_module_structure(model.decoder, os.path.join(output_dir, \"decoder.txt\"), \"Decoder\")\n",
    "\n",
    "    # === Print parameter summaries ===\n",
    "    print(\"\\nüßÆ === MODEL PARAMETER SUMMARY ===\")\n",
    "    summarize_model_parameters(model, \"Full Model\")\n",
    "    summarize_model_parameters(model.encoder, \"Encoder\")\n",
    "    summarize_model_parameters(model.ctc, \"CTC Head\")\n",
    "    if hasattr(model, \"decoder\"):\n",
    "        summarize_model_parameters(model.decoder, \"Decoder\")\n",
    "\n",
    "    print(f\"‚úÖ Done! Saved model structure to folder: {output_dir}\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfca96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e58774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233e085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe566546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt_lab (conda)",
   "language": "python",
   "name": "stt_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
