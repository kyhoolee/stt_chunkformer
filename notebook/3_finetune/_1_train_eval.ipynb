{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af15a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kylh/.local/share/mamba/envs/stt310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[2025-07-18 15:56:26] INFO: Checkpoint: loading from checkpoint ../../../chunkformer-large-vie/pytorch_model.bin for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧾 Loaded checkpoint from: ../../../chunkformer-large-vie/pytorch_model.bin\n",
      "📦 Checkpoint keys: ['encoder.global_cmvn.mean', 'encoder.global_cmvn.istd', 'encoder.embed.out.weight', 'encoder.embed.out.bias', 'encoder.embed.conv.0.weight'] ... (total 813)\n",
      "🔍 AED decoder head included in checkpoint? ✅ YES\n",
      "📊 Model total params: 113,852,240, trainable: 113,852,240\n",
      "!!!Vocab size: 6992\n",
      "\n",
      "🧪 Đánh giá mô hình trước khi fine-tune:\n",
      "🎯 Dev WER (CTC): 6.57%\n",
      "\n",
      "🌀 Epoch 1 bắt đầu...\n",
      "[Epoch 1 Step 1/6 | Global-Step 0] loss=0.3696 (ctc=0.2566, att=0.4181) grad=1.31  lr=9.99e-05 | ⏱️ 11.01s/step - ETA: 0m55s\n",
      "[Epoch 1 Step 2/6 | Global-Step 0] loss=0.2781 (ctc=0.1455, att=0.3349) grad=2.46  lr=9.97e-05 | ⏱️ 10.66s/step - ETA: 0m42s\n",
      "[Epoch 1 Step 3/6 | Global-Step 0] loss=0.1703 (ctc=0.1034, att=0.1990) grad=1.21  lr=9.94e-05 | ⏱️ 10.23s/step - ETA: 0m30s\n",
      "[Epoch 1 Step 4/6 | Global-Step 0] loss=0.0913 (ctc=0.0228, att=0.1206) grad=0.57  lr=9.89e-05 | ⏱️ 10.36s/step - ETA: 0m20s\n",
      "[Epoch 1 Step 5/6 | Global-Step 0] loss=0.0808 (ctc=0.0091, att=0.1115) grad=0.36  lr=9.83e-05 | ⏱️ 10.48s/step - ETA: 0m10s\n",
      "[Epoch 1 Step 6/6 | Global-Step 0] loss=0.0875 (ctc=0.0060, att=0.1225) grad=0.53  lr=9.76e-05 | ⏱️ 8.25s/step - ETA: 0m0s\n",
      "✅ Epoch 1 hoàn tất trong 1m1s\n",
      "💾 Đã lưu checkpoint: checkpoints/epoch1.pt\n",
      "🎯 Dev WER (CTC): 6.57%\n",
      "\n",
      "🌀 Epoch 2 bắt đầu...\n",
      "[Epoch 2 Step 1/6 | Global-Step 0] loss=0.0419 (ctc=0.0021, att=0.0589) grad=0.25  lr=9.67e-05 | ⏱️ 10.33s/step - ETA: 0m51s\n",
      "[Epoch 2 Step 2/6 | Global-Step 0] loss=0.0943 (ctc=0.0078, att=0.1314) grad=0.30  lr=9.57e-05 | ⏱️ 10.22s/step - ETA: 0m40s\n",
      "[Epoch 2 Step 3/6 | Global-Step 0] loss=0.0406 (ctc=0.0044, att=0.0561) grad=0.20  lr=9.46e-05 | ⏱️ 10.36s/step - ETA: 0m31s\n",
      "[Epoch 2 Step 4/6 | Global-Step 0] loss=0.0458 (ctc=0.0062, att=0.0628) grad=0.21  lr=9.34e-05 | ⏱️ 10.33s/step - ETA: 0m20s\n",
      "[Epoch 2 Step 5/6 | Global-Step 0] loss=0.0537 (ctc=0.0054, att=0.0744) grad=0.31  lr=9.20e-05 | ⏱️ 10.52s/step - ETA: 0m10s\n",
      "[Epoch 2 Step 6/6 | Global-Step 0] loss=0.0335 (ctc=0.0030, att=0.0466) grad=0.22  lr=9.05e-05 | ⏱️ 8.19s/step - ETA: 0m0s\n",
      "✅ Epoch 2 hoàn tất trong 1m0s\n",
      "💾 Đã lưu checkpoint: checkpoints/epoch2.pt\n",
      "🎯 Dev WER (CTC): 6.57%\n",
      "\n",
      "🌀 Epoch 3 bắt đầu...\n",
      "[Epoch 3 Step 1/6 | Global-Step 0] loss=0.0243 (ctc=0.0011, att=0.0342) grad=0.20  lr=8.90e-05 | ⏱️ 9.93s/step - ETA: 0m49s\n",
      "[Epoch 3 Step 2/6 | Global-Step 0] loss=0.0599 (ctc=0.0070, att=0.0826) grad=0.22  lr=8.73e-05 | ⏱️ 9.49s/step - ETA: 0m37s\n",
      "[Epoch 3 Step 3/6 | Global-Step 0] loss=0.0328 (ctc=0.0023, att=0.0459) grad=0.10  lr=8.55e-05 | ⏱️ 9.83s/step - ETA: 0m29s\n",
      "[Epoch 3 Step 4/6 | Global-Step 0] loss=0.0325 (ctc=0.0039, att=0.0448) grad=0.13  lr=8.36e-05 | ⏱️ 9.68s/step - ETA: 0m19s\n",
      "[Epoch 3 Step 5/6 | Global-Step 0] loss=0.0367 (ctc=0.0031, att=0.0512) grad=0.09  lr=8.17e-05 | ⏱️ 9.62s/step - ETA: 0m9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m CFG_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../config/finetune_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 🔥 Gọi đúng hàm run_train (đã chỉnh sửa ở bước 1)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mfine_tune_main\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoke\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/stt_chunkformer/chunkformer_vpb/training/train.py:72\u001b[0m, in \u001b[0;36mrun_train\u001b[0;34m(cfg_path, smoke)\u001b[0m\n\u001b[1;32m     69\u001b[0m feats, feat_lens \u001b[38;5;241m=\u001b[39m feats\u001b[38;5;241m.\u001b[39mto(device), feat_lens\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m toks,  tok_lens  \u001b[38;5;241m=\u001b[39m toks\u001b[38;5;241m.\u001b[39mto(device),  tok_lens\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 72\u001b[0m loss, loss_ctc, loss_att \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss_batch_v1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     77\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/work/stt_chunkformer/chunkformer_vpb/training/finetune_utils.py:320\u001b[0m, in \u001b[0;36mcompute_loss_batch_v1\u001b[0;34m(model, feats, feat_lens, toks, tok_lens, cfg, device)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_loss_batch_v1\u001b[39m(\n\u001b[1;32m    310\u001b[0m     model: ASRModel,\n\u001b[1;32m    311\u001b[0m     feats: torch\u001b[38;5;241m.\u001b[39mTensor,      \u001b[38;5;66;03m# [B, T_raw, D]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m \n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# 1) Offline‐encode cả batch\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     enc_outs, enc_masks \u001b[38;5;241m=\u001b[39m \u001b[43mencode_offline_batch_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m# enc_outs: [B, T_enc, D], enc_masks: [B,1,T_enc]\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     enc_lens \u001b[38;5;241m=\u001b[39m enc_masks\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mlong)  \u001b[38;5;66;03m# [B]\u001b[39;00m\n",
      "File \u001b[0;32m~/work/stt_chunkformer/chunkformer_vpb/training/finetune_utils.py:281\u001b[0m, in \u001b[0;36mencode_offline_batch_debug\u001b[0;34m(feats, feat_lens, model, chunk_cfg, device)\u001b[0m\n\u001b[1;32m    278\u001b[0m l_i \u001b[38;5;241m=\u001b[39m feat_lens[i]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# print(f\"  [sample {i}] raw_feat.shape = {x_i.shape}, raw_len = {l_i}\")\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m out_i, m_i \u001b[38;5;241m=\u001b[39m \u001b[43m_chunk_encoder_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# out_i: [N_chunk_i, chunk_len, D], m_i: [1, 1, T_chunk]\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# print(f\"    → after chunk-fwd: out_i.shape = {out_i.shape}, mask_i.shape = {m_i.shape}\")\u001b[39;00m\n\u001b[1;32m    285\u001b[0m all_chunks\u001b[38;5;241m.\u001b[39mappend(out_i)                        \u001b[38;5;66;03m# [N_chunk_i, chunk_len, D]\u001b[39;00m\n",
      "File \u001b[0;32m~/work/stt_chunkformer/chunkformer_vpb/training/finetune_utils.py:201\u001b[0m, in \u001b[0;36m_chunk_encoder_forward\u001b[0;34m(xs, model, chunk_cfg, device)\u001b[0m\n\u001b[1;32m    199\u001b[0m x \u001b[38;5;241m=\u001b[39m xs[:, start:end\u001b[38;5;241m+\u001b[39mrel_right]\n\u001b[1;32m    200\u001b[0m x_len \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 201\u001b[0m out, out_len, _, att_cache, cnn_cache, offset \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_parallel_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxs_origin_lens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_context_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_context_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43matt_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matt_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcnn_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcnn_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncated_context_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m chunks\u001b[38;5;241m.\u001b[39mappend(out[:, :out_len])\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m+\u001b[39m rel_right \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m xs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[0;32m~/work/stt_chunkformer/chunkformer_vpb/model/encoder.py:290\u001b[0m, in \u001b[0;36mBaseEncoder.forward_parallel_chunk\u001b[0;34m(self, xs, xs_origin_lens, chunk_size, left_context_size, right_context_size, att_cache, cnn_cache, truncated_context_size, offset)\u001b[0m\n\u001b[1;32m    288\u001b[0m r_att_cache, r_cnn_cache \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoders):\n\u001b[0;32m--> 290\u001b[0m     xs, _, new_att_cache, new_cnn_cache \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_parallel_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_pad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_context_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_context_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_context_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_context_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43matt_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matt_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43matt_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43matt_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcnn_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcnn_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcnn_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcnn_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncated_context_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncated_context_size\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     r_att_cache\u001b[38;5;241m.\u001b[39mappend(new_att_cache)\n\u001b[1;32m    300\u001b[0m     r_cnn_cache\u001b[38;5;241m.\u001b[39mappend(new_cnn_cache)\n",
      "File \u001b[0;32m~/work/stt_chunkformer/chunkformer_vpb/model/encoder_layer.py:151\u001b[0m, in \u001b[0;36mChunkFormerEncoderLayer.forward_parallel_chunk\u001b[0;34m(self, x, mask, pos_emb, mask_pad, att_cache, cnn_cache, right_context_size, left_context_size, truncated_context_size)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_before:\n\u001b[1;32m    149\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_ff(x)\n\u001b[0;32m--> 151\u001b[0m x_ff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# → (batch, time, dim)\u001b[39;00m\n\u001b[1;32m    152\u001b[0m x \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_scale \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x_ff)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_before:\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/stt310/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/stt310/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/stt_chunkformer/chunkformer_vpb/model/positionwise_feed_forward.py:53\u001b[0m, in \u001b[0;36mPositionwiseFeedForward.forward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, xs: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward function.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m        output tensor, (B, L, D)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m)))\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/stt310/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/stt310/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/stt310/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/stt310/lib/python3.10/site-packages/torch/fx/traceback.py:67\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/stt310/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/stt310/lib/python3.10/traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/stt310/lib/python3.10/linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from chunkformer_vpb.training import train as fine_tune_main\n",
    "\n",
    "CFG_PATH = \"../../config/finetune_config.yaml\"\n",
    "\n",
    "# 🔥 Gọi đúng hàm run_train (đã chỉnh sửa ở bước 1)\n",
    "fine_tune_main.run_train(cfg_path=CFG_PATH, smoke=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f3a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec84898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12933917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2cad76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26287f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stt310)",
   "language": "python",
   "name": "stt310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
