[2025-07-11 11:54:33] INFO: Checkpoint: loading from checkpoint ../../../chunkformer-large-vie/pytorch_model.bin for GPU

ğŸ§¾ Loaded checkpoint from: ../../../chunkformer-large-vie/pytorch_model.bin
ğŸ“¦ Checkpoint keys: ['encoder.global_cmvn.mean', 'encoder.global_cmvn.istd', 'encoder.embed.out.weight', 'encoder.embed.out.bias', 'encoder.embed.conv.0.weight'] ... (total 813)
ğŸ” AED decoder head included in checkpoint? âœ… YES
ğŸ“Š Model total params: 113,852,240, trainable: 113,852,240
âœ… Loaded state_dict with:
   ğŸ”º Missing keys: 2
     - encoder.ctc.ctc_lo.weight
     - encoder.ctc.ctc_lo.bias
   âš ï¸ Unexpected keys in checkpoint: 166
     - decoder.left_decoder.embed.0.weight
     - decoder.left_decoder.after_norm.weight
     - decoder.left_decoder.after_norm.bias
     - decoder.left_decoder.output_layer.weight
     - decoder.left_decoder.output_layer.bias
     - decoder.left_decoder.decoders.0.self_attn.linear_q.weight
     - decoder.left_decoder.decoders.0.self_attn.linear_q.bias
     - decoder.left_decoder.decoders.0.self_attn.linear_k.weight
     - decoder.left_decoder.decoders.0.self_attn.linear_k.bias
     - decoder.left_decoder.decoders.0.self_attn.linear_v.weight
     ...

=== Inspect utt_002968 ===
WAV  : shape=(1, 211000), sr=16000, min=-0.70, max=0.67
Feat : shape=(1317, 80), dtype=torch.float32, min=-0.6255, max=26.0976
Recompute fbank diff mean: 20.792910

ğŸ“¥ Loading file: cache_test/raw/utt_002968.wav
ğŸ” [pydub] Raw frame_rate   : 16000
ğŸ” [pydub] Sample width     : 2 bytes (16 bits)
ğŸ” [pydub] Channels         : 1
ğŸ” [pydub] Duration (ms)    : 13188 ms
ğŸ§ª [pydub] Type of array     : <class 'array.array'>, dtype: int16
ğŸ§ª [pydub] First 10 samples  : array('h', [0, 0, 0, -1, 1, -1, 9, 24, 28, 20])
âœ… [pydub] Waveform shape    : torch.Size([1, 211000])
ğŸ“Š [pydub] Min: -22931.00, Max: 21890.00, Mean: 0.01

ğŸ” [Compare] Loading with torchaudio.load()
âœ… [torchaudio] shape        : torch.Size([1, 211000]), sample_rate: 16000
ğŸ“Š [torchaudio] Min: -0.6998, Max: 0.6680, Mean: 0.0000
ğŸ“ Diff (mean abs): 0.0000 (assuming torchaudio gives normalized)

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 1317, 80]), xs_origin_lens: [1317]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=1317, padded_len=1543, pad_frames=226, n_chunks=3, offset=0

ğŸ§± Total chunked xs shape: torch.Size([3, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([3]), total_chunks: 3
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([3, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([3, 1, 320]), mask_pad shape: torch.Size([3, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [163]

âœ… [Encoder Output] xs: torch.Size([3, 64, 512]), xs_lens: [163], n_chunks: [3]
====================================================================


ğŸ“Š Total full_framewise_ids shape: torch.Size([163])
    Sample token IDs (first 20): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

ğŸ“ Decoded segments (first 3):
  â†’ {'decode': ' má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t hiá»‡n bá»“i dÆ°á»¡ng Ä‘á»ƒ Ä‘Æ°a ngÆ°á»i tháº­m chÃ­ cÃ²n giá»i hÆ¡n mÃ¬nh vÃ o vá»‹ trÃ­ thay mÃ¬nh', 'start': '00:00:02:000', 'end': '00:00:11:200'}

âœ… Final transcript:  má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t hiá»‡n bá»“i dÆ°á»¡ng Ä‘á»ƒ Ä‘Æ°a ngÆ°á»i tháº­m chÃ­ cÃ²n giá»i hÆ¡n mÃ¬nh vÃ o vá»‹ trÃ­ thay mÃ¬nh

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 1317, 80]), xs_origin_lens: [1317]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=1317, padded_len=1543, pad_frames=226, n_chunks=3, offset=0

ğŸ§± Total chunked xs shape: torch.Size([3, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([3]), total_chunks: 3
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([3, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([3, 1, 320]), mask_pad shape: torch.Size([3, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [163]

âœ… [Encoder Output] xs: torch.Size([3, 64, 512]), xs_lens: [163], n_chunks: [3]
====================================================================

ğŸ“£ AED RAW   : â–má»™tâ–ngÆ°á»iâ–lÃ£nhâ–Ä‘áº¡oâ–thÃ nhâ–cÃ´ngâ–lÃ â–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–lÃ£nhâ–Ä‘áº¡oâ–thÃ nhâ–cÃ´ngâ–lÃ â–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–lÃ£nhâ–Ä‘áº¡oâ–thÃ nhâ–cÃ´ngâ–lÃ â–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–lÃ£nhâ–Ä‘áº¡oâ–thÃ nhâ–cÃ´ngâ–lÃ â–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–lÃ£nhâ–Ä‘áº¡oâ–thÃ nhâ–cÃ´ngâ–lÃ â–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn<sos/eos>â–má»™tâ–ngÆ°á»iâ–lÃ£nhâ–Ä‘áº¡oâ–thÃ nhâ–cÃ´ngâ–lÃ â–ngÆ°á»iâ–phÃ¡tâ–triá»ƒn
ğŸ“£ AED CLEAN : má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn
CTC :  má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t hiá»‡n bá»“i dÆ°á»¡ng Ä‘á»ƒ Ä‘Æ°a ngÆ°á»i tháº­m chÃ­ cÃ²n giá»i hÆ¡n mÃ¬nh vÃ o vá»‹ trÃ­ thay mÃ¬nh
AED : má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i phÃ¡t triá»ƒn<sos/eos> má»™t ngÆ°á»i lÃ£nh Ä‘áº¡o thÃ nh cÃ´ng lÃ  ngÆ°á»i phÃ¡t triá»ƒn
GT  : Má»˜T NGÆ¯á»œI LÃƒNH Äáº O THÃ€NH CÃ”NG LÃ€ NGÆ¯á»œI PHÃT HIá»†N Bá»’I DÆ¯á» NG Äá»‚ ÄÆ¯A NGÆ¯á»œI THáº¬M CHÃ CÃ’N GIá»I HÆ N MÃŒNH VÃ€O Vá»Š TRÃ THAY MÃŒNH

=== Inspect utt_002025 ===
WAV  : shape=(1, 62990), sr=16000, min=-0.77, max=0.75
Feat : shape=(392, 80), dtype=torch.float32, min=3.9617, max=25.7422
Recompute fbank diff mean: 20.794363

ğŸ“¥ Loading file: cache_test/raw/utt_002025.wav
ğŸ” [pydub] Raw frame_rate   : 16000
ğŸ” [pydub] Sample width     : 2 bytes (16 bits)
ğŸ” [pydub] Channels         : 1
ğŸ” [pydub] Duration (ms)    : 3937 ms
ğŸ§ª [pydub] Type of array     : <class 'array.array'>, dtype: int16
ğŸ§ª [pydub] First 10 samples  : array('h', [-402, -663, -322, 65, -19, 102, 114, 229, 365, 253])
âœ… [pydub] Waveform shape    : torch.Size([1, 62990])
ğŸ“Š [pydub] Min: -25127.00, Max: 24582.00, Mean: -0.22

ğŸ” [Compare] Loading with torchaudio.load()
âœ… [torchaudio] shape        : torch.Size([1, 62990]), sample_rate: 16000
ğŸ“Š [torchaudio] Min: -0.7668, Max: 0.7502, Mean: -0.0000
ğŸ“ Diff (mean abs): 0.0000 (assuming torchaudio gives normalized)

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 392, 80]), xs_origin_lens: [392]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=392, padded_len=519, pad_frames=127, n_chunks=1, offset=0

ğŸ§± Total chunked xs shape: torch.Size([1, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([1]), total_chunks: 1
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([1, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([1, 1, 320]), mask_pad shape: torch.Size([1, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [48]

âœ… [Encoder Output] xs: torch.Size([1, 64, 512]), xs_lens: [48], n_chunks: [1]
====================================================================


ğŸ“Š Total full_framewise_ids shape: torch.Size([48])
    Sample token IDs (first 20): [0, 0, 0, 0, 6285, 0, 0, 4217, 0, 4532, 0, 0, 3565, 0, 0, 6263, 0, 0, 0, 0]

ğŸ“ Decoded segments (first 3):
  â†’ {'decode': ' vÃ  ngÃ y nÃ o lÃ m viá»‡c khÃ´ng thiá»‡n con cho má»™t háº¡t Ä‘áº­u Ä‘en', 'start': '00:00:00:000', 'end': '00:00:03:760'}

âœ… Final transcript:  vÃ  ngÃ y nÃ o lÃ m viá»‡c khÃ´ng thiá»‡n con cho má»™t háº¡t Ä‘áº­u Ä‘en

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 392, 80]), xs_origin_lens: [392]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=392, padded_len=519, pad_frames=127, n_chunks=1, offset=0

ğŸ§± Total chunked xs shape: torch.Size([1, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([1]), total_chunks: 1
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([1, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([1, 1, 320]), mask_pad shape: torch.Size([1, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [48]

âœ… [Encoder Output] xs: torch.Size([1, 64, 512]), xs_lens: [48], n_chunks: [1]
====================================================================

ğŸ“£ AED RAW   : â–vÃ â–ngÃ yâ–nÃ oâ–lÃ mâ–viá»‡câ–khÃ´ngâ–thiá»‡nâ–conâ–choâ–má»™tâ–háº¡tâ–Ä‘áº­uâ–Ä‘en<sos/eos>
ğŸ“£ AED CLEAN : vÃ  ngÃ y nÃ o lÃ m viá»‡c khÃ´ng thiá»‡n con cho má»™t háº¡t Ä‘áº­u Ä‘en<sos/eos>
CTC :  vÃ  ngÃ y nÃ o lÃ m viá»‡c khÃ´ng thiá»‡n con cho má»™t háº¡t Ä‘áº­u Ä‘en
AED : vÃ  ngÃ y nÃ o lÃ m viá»‡c khÃ´ng thiá»‡n con cho má»™t háº¡t Ä‘áº­u Ä‘en<sos/eos>
GT  : VÃ€ NGÃ€Y NÃ€O LÃ€M VIá»†C KHÃ”NG THIá»†N CON CHO Má»˜T Háº T Äáº¬U ÄEN

=== Inspect utt_009178 ===
WAV  : shape=(1, 37000), sr=16000, min=-0.36, max=0.37
Feat : shape=(229, 80), dtype=torch.float32, min=1.8229, max=24.9941
Recompute fbank diff mean: 20.793457

ğŸ“¥ Loading file: cache_test/raw/utt_009178.wav
ğŸ” [pydub] Raw frame_rate   : 16000
ğŸ” [pydub] Sample width     : 2 bytes (16 bits)
ğŸ” [pydub] Channels         : 1
ğŸ” [pydub] Duration (ms)    : 2312 ms
ğŸ§ª [pydub] Type of array     : <class 'array.array'>, dtype: int16
ğŸ§ª [pydub] First 10 samples  : array('h', [0, 0, -1, 0, 0, -1, 4, 15, 6, -4])
âœ… [pydub] Waveform shape    : torch.Size([1, 37000])
ğŸ“Š [pydub] Min: -11679.00, Max: 12195.00, Mean: -0.03

ğŸ” [Compare] Loading with torchaudio.load()
âœ… [torchaudio] shape        : torch.Size([1, 37000]), sample_rate: 16000
ğŸ“Š [torchaudio] Min: -0.3564, Max: 0.3722, Mean: -0.0000
ğŸ“ Diff (mean abs): 0.0000 (assuming torchaudio gives normalized)

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 229, 80]), xs_origin_lens: [229]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=229, padded_len=519, pad_frames=290, n_chunks=1, offset=0

ğŸ§± Total chunked xs shape: torch.Size([1, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([1]), total_chunks: 1
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([1, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([1, 1, 320]), mask_pad shape: torch.Size([1, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [27]

âœ… [Encoder Output] xs: torch.Size([1, 64, 512]), xs_lens: [27], n_chunks: [1]
====================================================================


ğŸ“Š Total full_framewise_ids shape: torch.Size([27])
    Sample token IDs (first 20): [0, 0, 0, 0, 0, 0, 0, 2137, 0, 0, 0, 4217, 0, 0, 0, 6969, 0, 0, 1576, 0]

ğŸ“ Decoded segments (first 3):
  â†’ {'decode': ' cáº£ ngÃ y á»Ÿ bÃªn anh', 'start': '00:00:00:000', 'end': '00:00:02:080'}

âœ… Final transcript:  cáº£ ngÃ y á»Ÿ bÃªn anh

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 229, 80]), xs_origin_lens: [229]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=229, padded_len=519, pad_frames=290, n_chunks=1, offset=0

ğŸ§± Total chunked xs shape: torch.Size([1, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([1]), total_chunks: 1
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([1, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([1, 1, 320]), mask_pad shape: torch.Size([1, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [27]

âœ… [Encoder Output] xs: torch.Size([1, 64, 512]), xs_lens: [27], n_chunks: [1]
====================================================================

ğŸ“£ AED RAW   : â–cáº£â–ngÃ yâ–á»Ÿâ–bÃªnâ–anh<sos/eos>
ğŸ“£ AED CLEAN : cáº£ ngÃ y á»Ÿ bÃªn anh<sos/eos>
CTC :  cáº£ ngÃ y á»Ÿ bÃªn anh
AED : cáº£ ngÃ y á»Ÿ bÃªn anh<sos/eos>
GT  : Cáº¢ NGÃ€Y á» BÃŠN ANH

=== Inspect utt_003842 ===
WAV  : shape=(1, 67000), sr=16000, min=-0.38, max=0.37
Feat : shape=(417, 80), dtype=torch.float32, min=-0.2564, max=25.3876
Recompute fbank diff mean: 20.793530

ğŸ“¥ Loading file: cache_test/raw/utt_003842.wav
ğŸ” [pydub] Raw frame_rate   : 16000
ğŸ” [pydub] Sample width     : 2 bytes (16 bits)
ğŸ” [pydub] Channels         : 1
ğŸ” [pydub] Duration (ms)    : 4188 ms
ğŸ§ª [pydub] Type of array     : <class 'array.array'>, dtype: int16
ğŸ§ª [pydub] First 10 samples  : array('h', [0, 0, -1, 1, -4, 8, -52, -107, -86, -110])
âœ… [pydub] Waveform shape    : torch.Size([1, 67000])
ğŸ“Š [pydub] Min: -12448.00, Max: 12090.00, Mean: 0.01

ğŸ” [Compare] Loading with torchaudio.load()
âœ… [torchaudio] shape        : torch.Size([1, 67000]), sample_rate: 16000
ğŸ“Š [torchaudio] Min: -0.3799, Max: 0.3690, Mean: 0.0000
ğŸ“ Diff (mean abs): 0.0000 (assuming torchaudio gives normalized)

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 417, 80]), xs_origin_lens: [417]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=417, padded_len=519, pad_frames=102, n_chunks=1, offset=0

ğŸ§± Total chunked xs shape: torch.Size([1, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([1]), total_chunks: 1
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([1, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([1, 1, 320]), mask_pad shape: torch.Size([1, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [51]

âœ… [Encoder Output] xs: torch.Size([1, 64, 512]), xs_lens: [51], n_chunks: [1]
====================================================================


ğŸ“Š Total full_framewise_ids shape: torch.Size([51])
    Sample token IDs (first 20): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2089, 0, 0, 0, 5605, 0]

ğŸ“ Decoded segments (first 3):
  â†’ {'decode': ' cÃ³ thÃ¢m Ã½ nhÆ¡n sinh Ä‘á»™c chiÃªu', 'start': '00:00:00:320', 'end': '00:00:04:000'}

âœ… Final transcript:  cÃ³ thÃ¢m Ã½ nhÆ¡n sinh Ä‘á»™c chiÃªu

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 417, 80]), xs_origin_lens: [417]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=417, padded_len=519, pad_frames=102, n_chunks=1, offset=0

ğŸ§± Total chunked xs shape: torch.Size([1, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([1]), total_chunks: 1
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([1, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([1, 1, 320]), mask_pad shape: torch.Size([1, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [51]

âœ… [Encoder Output] xs: torch.Size([1, 64, 512]), xs_lens: [51], n_chunks: [1]
====================================================================

ğŸ“£ AED RAW   : â–cÃ³â–thÃ¢mâ–Ã½â–nhÃ¢nâ–sinhâ–Ä‘á»™câ–chiÃªu<sos/eos>
ğŸ“£ AED CLEAN : cÃ³ thÃ¢m Ã½ nhÃ¢n sinh Ä‘á»™c chiÃªu<sos/eos>
CTC :  cÃ³ thÃ¢m Ã½ nhÆ¡n sinh Ä‘á»™c chiÃªu
AED : cÃ³ thÃ¢m Ã½ nhÃ¢n sinh Ä‘á»™c chiÃªu<sos/eos>
GT  : CÃ“ THÃ‚M Ã NHÆ N SINH Äá»˜C CHIÃŠU

=== Inspect utt_008670 ===
WAV  : shape=(1, 98500), sr=16000, min=-0.99, max=1.00
Feat : shape=(614, 80), dtype=torch.float32, min=3.9155, max=26.2756
Recompute fbank diff mean: 20.794378

ğŸ“¥ Loading file: cache_test/raw/utt_008670.wav
ğŸ” [pydub] Raw frame_rate   : 16000
ğŸ” [pydub] Sample width     : 2 bytes (16 bits)
ğŸ” [pydub] Channels         : 1
ğŸ” [pydub] Duration (ms)    : 6156 ms
ğŸ§ª [pydub] Type of array     : <class 'array.array'>, dtype: int16
ğŸ§ª [pydub] First 10 samples  : array('h', [-1, 0, -1, 1, -2, 3, -10, -1, -8, -27])
âœ… [pydub] Waveform shape    : torch.Size([1, 98500])
ğŸ“Š [pydub] Min: -32539.00, Max: 32767.00, Mean: -1.56

ğŸ” [Compare] Loading with torchaudio.load()
âœ… [torchaudio] shape        : torch.Size([1, 98500]), sample_rate: 16000
ğŸ“Š [torchaudio] Min: -0.9930, Max: 1.0000, Mean: -0.0000
ğŸ“ Diff (mean abs): 0.0000 (assuming torchaudio gives normalized)

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 614, 80]), xs_origin_lens: [614]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=614, padded_len=1031, pad_frames=417, n_chunks=2, offset=0

ğŸ§± Total chunked xs shape: torch.Size([2, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([2]), total_chunks: 2
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([2, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([2, 1, 320]), mask_pad shape: torch.Size([2, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [75]

âœ… [Encoder Output] xs: torch.Size([2, 64, 512]), xs_lens: [75], n_chunks: [2]
====================================================================


ğŸ“Š Total full_framewise_ids shape: torch.Size([75])
    Sample token IDs (first 20): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2096, 0, 6263, 0, 0, 0, 2588, 0, 1821]

ğŸ“ Decoded segments (first 3):
  â†’ {'decode': ' cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m vá» cháº¥t lÆ°á»£ng', 'start': '00:00:00:080', 'end': '00:00:05:920'}

âœ… Final transcript:  cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m vá» cháº¥t lÆ°á»£ng

================= ğŸ§© [Encoder.forward_parallel_chunk] START =================
ğŸ“¥ Input shape: torch.Size([1, 614, 80]), xs_origin_lens: [614]
âš™ï¸ chunk_size=64, left_context=128, right_context=128, truncated_context_size=11200
ğŸ“ Subsampling: 8, Chunk frame size: 519, Step: 512, Conv lorder: 7
ğŸ”¹ Sample 0: original_len=614, padded_len=1031, pad_frames=417, n_chunks=2, offset=0

ğŸ§± Total chunked xs shape: torch.Size([2, 519, 80])
ğŸ“ xs_lens (post chunk): torch.Size([2]), total_chunks: 2
âœ… Applied Global CMVN
ğŸ›ï¸ Embedded xs shape: torch.Size([2, 64, 512]), PosEmb shape: torch.Size([1, 383, 512])
ğŸ§® att_mask shape: torch.Size([2, 1, 320]), mask_pad shape: torch.Size([2, 1, 78])
ğŸ“ Applied LayerNorm after encoder
ğŸ“¤ Final offset: [75]

âœ… [Encoder Output] xs: torch.Size([2, 64, 512]), xs_lens: [75], n_chunks: [2]
====================================================================

ğŸ“£ AED RAW   : â–cÃ´ngâ–viá»‡câ–giaoâ–choâ–há»â–khÃ´ngâ–pháº£iâ–máº¥tâ–nhiá»uâ–thá»iâ–gianâ–Ä‘á»ƒâ–kiá»ƒmâ–traâ–láº¡iâ–vÃ â–khÃ¡â–yÃªnâ–tÃ¢m<sos/eos>â–cÃ´ngâ–viá»‡câ–giaoâ–choâ–há»â–khÃ´ngâ–pháº£iâ–máº¥tâ–nhiá»uâ–thá»iâ–gianâ–Ä‘á»ƒâ–kiá»ƒmâ–traâ–láº¡iâ–vÃ â–khÃ¡â–yÃªnâ–tÃ¢m<sos/eos>â–cÃ´ngâ–viá»‡câ–giaoâ–choâ–há»â–khÃ´ngâ–pháº£i<sos/eos>â–cÃ´ngâ–viá»‡câ–giaoâ–choâ–há»â–khÃ´ngâ–pháº£iâ–máº¥tâ–nhiá»uâ–thá»iâ–gianâ–Ä‘á»ƒâ–kiá»ƒmâ–traâ–láº¡iâ–vÃ â–khÃ¡â–yÃªnâ–tÃ¢m<sos/eos>â–cÃ´ngâ–viá»‡câ–giaoâ–choâ–há»â–khÃ´ngâ–pháº£i<sos/eos>â–cÃ´ngâ–viá»‡câ–giaoâ–choâ–há»â–khÃ´ngâ–pháº£iâ–máº¥tâ–nhiá»uâ–thá»iâ–gianâ–Ä‘á»ƒâ–kiá»ƒmâ–traâ–láº¡iâ–vÃ â–khÃ¡â–yÃªnâ–tÃ¢m<sos/eos>â–cÃ´ngâ–viá»‡câ–giaoâ–cho
ğŸ“£ AED CLEAN : cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m<sos/eos> cÃ´ng viá»‡c giao cho
CTC :  cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m vá» cháº¥t lÆ°á»£ng
AED : cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i<sos/eos> cÃ´ng viá»‡c giao cho há» khÃ´ng pháº£i máº¥t nhiá»u thá»i gian Ä‘á»ƒ kiá»ƒm tra láº¡i vÃ  khÃ¡ yÃªn tÃ¢m<sos/eos> cÃ´ng viá»‡c giao cho
GT  : CÃ”NG VIá»†C GIAO CHO Há»Œ KHÃ”NG PHáº¢I Máº¤T NHIá»€U THá»œI GIAN Äá»‚ KIá»‚M TRA Láº I VÃ€ KHÃ YÃŠN TÃ‚M Vá»€ CHáº¤T LÆ¯á»¢NG
